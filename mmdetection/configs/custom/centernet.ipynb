{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 import\n",
    "\n",
    "from mmcv import Config\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)\n",
    "from mmdet.utils import get_device\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile('./centernet_resnet18_dcnv2_140e_coco.py')\n",
    "cfg.seed = 2022\n",
    "cfg.gpu_ids = [0]\n",
    "cfg.work_dir = './work_dirs/centernet_resnet18_140e_coco'\n",
    "cfg.device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# build_dataset\n",
    "datasets = [build_dataset(cfg.data.train.dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CocoDataset Train dataset with number of images 3914, and instance counts: \n",
      "+-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+\n",
      "| category          | count | category      | count | category        | count | category    | count | category     | count |\n",
      "+-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+\n",
      "| 0 [General trash] | 3161  | 1 [Paper]     | 5115  | 2 [Paper pack]  | 706   | 3 [Metal]   | 769   | 4 [Glass]    | 835   |\n",
      "| 5 [Plastic]       | 2350  | 6 [Styrofoam] | 1026  | 7 [Plastic bag] | 4151  | 8 [Battery] | 143   | 9 [Clothing] | 377   |\n",
      "+-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+\n"
     ]
    }
   ],
   "source": [
    "print(datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 17:08:19,106 - mmcv - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet18'}\n",
      "2024-01-15 17:08:19,108 - mmcv - INFO - load model from: torchvision://resnet18\n",
      "2024-01-15 17:08:19,109 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet18\n",
      "2024-01-15 17:08:19,228 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "2024-01-15 17:08:19,269 - mmcv - INFO - \n",
      "backbone.conv1.weight - torch.Size([64, 3, 7, 7]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,270 - mmcv - INFO - \n",
      "backbone.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,271 - mmcv - INFO - \n",
      "backbone.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,272 - mmcv - INFO - \n",
      "backbone.layer1.0.conv1.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,272 - mmcv - INFO - \n",
      "backbone.layer1.0.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,273 - mmcv - INFO - \n",
      "backbone.layer1.0.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,274 - mmcv - INFO - \n",
      "backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,274 - mmcv - INFO - \n",
      "backbone.layer1.0.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,275 - mmcv - INFO - \n",
      "backbone.layer1.0.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,277 - mmcv - INFO - \n",
      "backbone.layer1.1.conv1.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,278 - mmcv - INFO - \n",
      "backbone.layer1.1.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,279 - mmcv - INFO - \n",
      "backbone.layer1.1.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,280 - mmcv - INFO - \n",
      "backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,281 - mmcv - INFO - \n",
      "backbone.layer1.1.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,281 - mmcv - INFO - \n",
      "backbone.layer1.1.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,282 - mmcv - INFO - \n",
      "backbone.layer2.0.conv1.weight - torch.Size([128, 64, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,283 - mmcv - INFO - \n",
      "backbone.layer2.0.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,284 - mmcv - INFO - \n",
      "backbone.layer2.0.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,285 - mmcv - INFO - \n",
      "backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,285 - mmcv - INFO - \n",
      "backbone.layer2.0.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,286 - mmcv - INFO - \n",
      "backbone.layer2.0.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,287 - mmcv - INFO - \n",
      "backbone.layer2.0.downsample.0.weight - torch.Size([128, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,287 - mmcv - INFO - \n",
      "backbone.layer2.0.downsample.1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,288 - mmcv - INFO - \n",
      "backbone.layer2.0.downsample.1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,289 - mmcv - INFO - \n",
      "backbone.layer2.1.conv1.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,289 - mmcv - INFO - \n",
      "backbone.layer2.1.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,290 - mmcv - INFO - \n",
      "backbone.layer2.1.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,291 - mmcv - INFO - \n",
      "backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,291 - mmcv - INFO - \n",
      "backbone.layer2.1.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,292 - mmcv - INFO - \n",
      "backbone.layer2.1.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,293 - mmcv - INFO - \n",
      "backbone.layer3.0.conv1.weight - torch.Size([256, 128, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,294 - mmcv - INFO - \n",
      "backbone.layer3.0.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,294 - mmcv - INFO - \n",
      "backbone.layer3.0.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,295 - mmcv - INFO - \n",
      "backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,296 - mmcv - INFO - \n",
      "backbone.layer3.0.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,296 - mmcv - INFO - \n",
      "backbone.layer3.0.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,297 - mmcv - INFO - \n",
      "backbone.layer3.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,298 - mmcv - INFO - \n",
      "backbone.layer3.0.downsample.1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,299 - mmcv - INFO - \n",
      "backbone.layer3.0.downsample.1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,300 - mmcv - INFO - \n",
      "backbone.layer3.1.conv1.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,300 - mmcv - INFO - \n",
      "backbone.layer3.1.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,301 - mmcv - INFO - \n",
      "backbone.layer3.1.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,302 - mmcv - INFO - \n",
      "backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,302 - mmcv - INFO - \n",
      "backbone.layer3.1.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,303 - mmcv - INFO - \n",
      "backbone.layer3.1.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,304 - mmcv - INFO - \n",
      "backbone.layer4.0.conv1.weight - torch.Size([512, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,305 - mmcv - INFO - \n",
      "backbone.layer4.0.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,305 - mmcv - INFO - \n",
      "backbone.layer4.0.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,306 - mmcv - INFO - \n",
      "backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,307 - mmcv - INFO - \n",
      "backbone.layer4.0.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,307 - mmcv - INFO - \n",
      "backbone.layer4.0.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,308 - mmcv - INFO - \n",
      "backbone.layer4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,309 - mmcv - INFO - \n",
      "backbone.layer4.0.downsample.1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,309 - mmcv - INFO - \n",
      "backbone.layer4.0.downsample.1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,310 - mmcv - INFO - \n",
      "backbone.layer4.1.conv1.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,311 - mmcv - INFO - \n",
      "backbone.layer4.1.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,312 - mmcv - INFO - \n",
      "backbone.layer4.1.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,312 - mmcv - INFO - \n",
      "backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,313 - mmcv - INFO - \n",
      "backbone.layer4.1.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,314 - mmcv - INFO - \n",
      "backbone.layer4.1.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet18 \n",
      " \n",
      "2024-01-15 17:08:19,314 - mmcv - INFO - \n",
      "neck.deconv_layers.0.conv.weight - torch.Size([256, 512, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of CenterNet  \n",
      " \n",
      "2024-01-15 17:08:19,315 - mmcv - INFO - \n",
      "neck.deconv_layers.0.conv.conv_offset.weight - torch.Size([27, 512, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of CenterNet  \n",
      " \n",
      "2024-01-15 17:08:19,315 - mmcv - INFO - \n",
      "neck.deconv_layers.0.conv.conv_offset.bias - torch.Size([27]): \n",
      "The value is the same before and after calling `init_weights` of CenterNet  \n",
      " \n",
      "2024-01-15 17:08:19,316 - mmcv - INFO - \n",
      "neck.deconv_layers.0.bn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CenterNet  \n",
      " \n",
      "2024-01-15 17:08:19,316 - mmcv - INFO - \n",
      "neck.deconv_layers.0.bn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CenterNet  \n",
      " \n",
      "2024-01-15 17:08:19,317 - mmcv - INFO - \n",
      "neck.deconv_layers.1.conv.weight - torch.Size([256, 256, 4, 4]): \n",
      "Initialized by user-defined `init_weights` in CTResNetNeck  \n",
      " \n",
      "2024-01-15 17:08:19,317 - mmcv - INFO - \n",
      "neck.deconv_layers.1.bn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CenterNet  \n",
      " \n",
      "2024-01-15 17:08:19,318 - mmcv - INFO - \n",
      "neck.deconv_layers.1.bn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CenterNet  \n",
      " \n",
      "2024-01-15 17:08:19,318 - mmcv - INFO - \n",
      "neck.deconv_layers.2.conv.weight - torch.Size([128, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of CenterNet  \n",
      " \n",
      "2024-01-15 17:08:19,319 - mmcv - INFO - \n",
      "neck.deconv_layers.2.conv.conv_offset.weight - torch.Size([27, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of CenterNet  \n",
      " \n",
      "2024-01-15 17:08:19,319 - mmcv - INFO - \n",
      "neck.deconv_layers.2.conv.conv_offset.bias - torch.Size([27]): \n",
      "The value is the same before and after calling `init_weights` of CenterNet  \n",
      " \n",
      "2024-01-15 17:08:19,320 - mmcv - INFO - \n",
      "neck.deconv_layers.2.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of CenterNet  \n",
      " \n",
      "2024-01-15 17:08:19,321 - mmcv - INFO - \n",
      "neck.deconv_layers.2.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of CenterNet  \n",
      " \n",
      "2024-01-15 17:08:19,321 - mmcv - INFO - \n",
      "neck.deconv_layers.3.conv.weight - torch.Size([128, 128, 4, 4]): \n",
      "Initialized by user-defined `init_weights` in CTResNetNeck  \n",
      " \n",
      "2024-01-15 17:08:19,322 - mmcv - INFO - \n",
      "neck.deconv_layers.3.bn.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of CenterNet  \n",
      " \n",
      "2024-01-15 17:08:19,322 - mmcv - INFO - \n",
      "neck.deconv_layers.3.bn.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of CenterNet  \n",
      " \n",
      "2024-01-15 17:08:19,323 - mmcv - INFO - \n",
      "neck.deconv_layers.4.conv.weight - torch.Size([64, 128, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of CenterNet  \n",
      " \n",
      "2024-01-15 17:08:19,323 - mmcv - INFO - \n",
      "neck.deconv_layers.4.conv.conv_offset.weight - torch.Size([27, 128, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of CenterNet  \n",
      " \n",
      "2024-01-15 17:08:19,324 - mmcv - INFO - \n",
      "neck.deconv_layers.4.conv.conv_offset.bias - torch.Size([27]): \n",
      "The value is the same before and after calling `init_weights` of CenterNet  \n",
      " \n",
      "2024-01-15 17:08:19,324 - mmcv - INFO - \n",
      "neck.deconv_layers.4.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of CenterNet  \n",
      " \n",
      "2024-01-15 17:08:19,325 - mmcv - INFO - \n",
      "neck.deconv_layers.4.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of CenterNet  \n",
      " \n",
      "2024-01-15 17:08:19,325 - mmcv - INFO - \n",
      "neck.deconv_layers.5.conv.weight - torch.Size([64, 64, 4, 4]): \n",
      "Initialized by user-defined `init_weights` in CTResNetNeck  \n",
      " \n",
      "2024-01-15 17:08:19,326 - mmcv - INFO - \n",
      "neck.deconv_layers.5.bn.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of CenterNet  \n",
      " \n",
      "2024-01-15 17:08:19,329 - mmcv - INFO - \n",
      "neck.deconv_layers.5.bn.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of CenterNet  \n",
      " \n",
      "2024-01-15 17:08:19,329 - mmcv - INFO - \n",
      "bbox_head.heatmap_head.0.weight - torch.Size([64, 64, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of CenterNet  \n",
      " \n",
      "2024-01-15 17:08:19,329 - mmcv - INFO - \n",
      "bbox_head.heatmap_head.0.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of CenterNet  \n",
      " \n",
      "2024-01-15 17:08:19,330 - mmcv - INFO - \n",
      "bbox_head.heatmap_head.2.weight - torch.Size([10, 64, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of CenterNet  \n",
      " \n",
      "2024-01-15 17:08:19,330 - mmcv - INFO - \n",
      "bbox_head.heatmap_head.2.bias - torch.Size([10]): \n",
      "Initialized by user-defined `init_weights` in CenterNetHead  \n",
      " \n",
      "2024-01-15 17:08:19,331 - mmcv - INFO - \n",
      "bbox_head.wh_head.0.weight - torch.Size([64, 64, 3, 3]): \n",
      "Initialized by user-defined `init_weights` in CenterNetHead  \n",
      " \n",
      "2024-01-15 17:08:19,331 - mmcv - INFO - \n",
      "bbox_head.wh_head.0.bias - torch.Size([64]): \n",
      "Initialized by user-defined `init_weights` in CenterNetHead  \n",
      " \n",
      "2024-01-15 17:08:19,331 - mmcv - INFO - \n",
      "bbox_head.wh_head.2.weight - torch.Size([2, 64, 1, 1]): \n",
      "Initialized by user-defined `init_weights` in CenterNetHead  \n",
      " \n",
      "2024-01-15 17:08:19,332 - mmcv - INFO - \n",
      "bbox_head.wh_head.2.bias - torch.Size([2]): \n",
      "Initialized by user-defined `init_weights` in CenterNetHead  \n",
      " \n",
      "2024-01-15 17:08:19,333 - mmcv - INFO - \n",
      "bbox_head.offset_head.0.weight - torch.Size([64, 64, 3, 3]): \n",
      "Initialized by user-defined `init_weights` in CenterNetHead  \n",
      " \n",
      "2024-01-15 17:08:19,333 - mmcv - INFO - \n",
      "bbox_head.offset_head.0.bias - torch.Size([64]): \n",
      "Initialized by user-defined `init_weights` in CenterNetHead  \n",
      " \n",
      "2024-01-15 17:08:19,333 - mmcv - INFO - \n",
      "bbox_head.offset_head.2.weight - torch.Size([2, 64, 1, 1]): \n",
      "Initialized by user-defined `init_weights` in CenterNetHead  \n",
      " \n",
      "2024-01-15 17:08:19,334 - mmcv - INFO - \n",
      "bbox_head.offset_head.2.bias - torch.Size([2]): \n",
      "Initialized by user-defined `init_weights` in CenterNetHead  \n",
      " \n"
     ]
    }
   ],
   "source": [
    "model = build_detector(cfg.model)\n",
    "model.init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 17:08:22,788 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
      "2024-01-15 17:08:22,792 - mmdet - INFO - Start running, host: root@instance-5464, work_dir: /data/ephemeral/home/baseline/mmdetection/configs/custom/work_dirs/centernet_resnet18_140e_coco\n",
      "2024-01-15 17:08:22,793 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2024-01-15 17:08:22,793 - mmdet - INFO - workflow: [('train', 1)], max: 28 epochs\n",
      "2024-01-15 17:08:22,794 - mmdet - INFO - Checkpoints will be saved to /data/ephemeral/home/baseline/mmdetection/configs/custom/work_dirs/centernet_resnet18_140e_coco by HardDiskBackend.\n",
      "2024-01-15 17:08:41,882 - mmdet - INFO - Epoch [1][50/245]\tlr: 9.990e-04, eta: 0:43:19, time: 0.382, data_time: 0.099, memory: 2800, loss_center_heatmap: 24.3408, loss_wh: 6.2309, loss_offset: 0.4810, loss: 31.0526, grad_norm: 97.8734\n",
      "2024-01-15 17:08:55,474 - mmdet - INFO - Epoch [1][100/245]\tlr: 1.998e-03, eta: 0:36:48, time: 0.272, data_time: 0.038, memory: 2800, loss_center_heatmap: 4.1775, loss_wh: 6.5476, loss_offset: 0.3637, loss: 11.0888, grad_norm: 19.5320\n",
      "2024-01-15 17:09:08,865 - mmdet - INFO - Epoch [1][150/245]\tlr: 2.997e-03, eta: 0:34:20, time: 0.268, data_time: 0.034, memory: 2800, loss_center_heatmap: 4.0637, loss_wh: 6.3231, loss_offset: 0.2810, loss: 10.6678, grad_norm: 15.6189\n",
      "2024-01-15 17:09:22,666 - mmdet - INFO - Epoch [1][200/245]\tlr: 3.996e-03, eta: 0:33:13, time: 0.276, data_time: 0.036, memory: 2800, loss_center_heatmap: 4.0434, loss_wh: 6.1863, loss_offset: 0.2671, loss: 10.4968, grad_norm: 12.2492\n",
      "2024-01-15 17:09:34,594 - mmdet - INFO - Saving checkpoint at 1 epochs\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistributed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/baseline/mmdetection/mmdet/apis/train.py:244\u001b[0m, in \u001b[0;36mtrain_detector\u001b[0;34m(model, dataset, cfg, distributed, validate, timestamp, meta)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mload_from:\n\u001b[1;32m    243\u001b[0m     runner\u001b[38;5;241m.\u001b[39mload_checkpoint(cfg\u001b[38;5;241m.\u001b[39mload_from)\n\u001b[0;32m--> 244\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmcv/runner/epoch_based_runner.py:136\u001b[0m, in \u001b[0;36mEpochBasedRunner.run\u001b[0;34m(self, data_loaders, workflow, max_epochs, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_epochs:\n\u001b[1;32m    135\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m             \u001b[43mepoch_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loaders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# wait for some hooks like loggers to finish\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_run\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmcv/runner/epoch_based_runner.py:49\u001b[0m, in \u001b[0;36mEpochBasedRunner.train\u001b[0;34m(self, data_loader, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_train_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     48\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Prevent possible deadlock during epoch transition\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_loader):\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_batch \u001b[38;5;241m=\u001b[39m data_batch\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_iter \u001b[38;5;241m=\u001b[39m i\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1359\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1362\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1325\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1325\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1326\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1327\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_detector(model, datasets[0], cfg, distributed=False, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
