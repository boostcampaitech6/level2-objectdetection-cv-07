{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "from mmcv import Config\n",
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import single_gpu_test\n",
    "from mmcv.runner import load_checkpoint\n",
    "import os\n",
    "from mmcv.parallel import MMDataParallel\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\", \n",
    "           \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\")\n",
    "\n",
    "\n",
    "cfg = Config.fromfile('./deformable_detr_twostage_refine_r50_16X2_50e_coco.py')\n",
    "\n",
    "root='../../../../dataset/'\n",
    "\n",
    "cfg.data.test.img_prefix = root\n",
    "cfg.data.test.ann_file = root + 'test.json'\n",
    "\n",
    "cfg.data.test.test_mode = True\n",
    "\n",
    "cfg.work_dir = './work_dirs/deformable_detr_twostage_refine_r50_16X2_50e_coco'\n",
    "\n",
    "epoch = 'latest'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ann_file': '../../../../dataset/test.json',\n",
      " 'classes': ('General trash',\n",
      "             'Paper',\n",
      "             'Paper pack',\n",
      "             'Metal',\n",
      "             'Glass',\n",
      "             'Plastic',\n",
      "             'Styrofoam',\n",
      "             'Plastic bag',\n",
      "             'Battery',\n",
      "             'Clothing'),\n",
      " 'img_prefix': '../../../../dataset/',\n",
      " 'pipeline': [{'type': 'LoadImageFromFile'},\n",
      "              {'flip': False,\n",
      "               'img_scale': (1333, 800),\n",
      "               'transforms': [{'keep_ratio': True, 'type': 'Resize'},\n",
      "                              {'type': 'RandomFlip'},\n",
      "                              {'mean': [123.675, 116.28, 103.53],\n",
      "                               'std': [58.395, 57.12, 57.375],\n",
      "                               'to_rgb': True,\n",
      "                               'type': 'Normalize'},\n",
      "                              {'size_divisor': 1, 'type': 'Pad'},\n",
      "                              {'keys': ['img'], 'type': 'ImageToTensor'},\n",
      "                              {'keys': ['img'], 'type': 'Collect'}],\n",
      "               'type': 'MultiScaleFlipAug'}],\n",
      " 'test_mode': True,\n",
      " 'type': 'CocoDataset'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(cfg.data.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.21s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# build dataset & dataloader\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        samples_per_gpu=1,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=False,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CocoDataset Test dataset with number of images 4871, and instance counts: \n",
      "+-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+\n",
      "| category          | count | category      | count | category        | count | category    | count | category     | count |\n",
      "+-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+\n",
      "| 0 [General trash] | 0     | 1 [Paper]     | 0     | 2 [Paper pack]  | 0     | 3 [Metal]   | 0     | 4 [Glass]    | 0     |\n",
      "| 5 [Plastic]       | 0     | 6 [Styrofoam] | 0     | 7 [Plastic bag] | 0     | 8 [Battery] | 0     | 9 [Clothing] | 0     |\n",
      "|                   |       |               |       |                 |       |             |       |              |       |\n",
      "| -1 background     | 4871  |               |       |                 |       |             |       |              |       |\n",
      "+-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+\n",
      "\n",
      "CocoDataset Test dataset with number of images 4871, and instance counts: \n",
      "+-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+\n",
      "| category          | count | category      | count | category        | count | category    | count | category     | count |\n",
      "+-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+\n",
      "| 0 [General trash] | 0     | 1 [Paper]     | 0     | 2 [Paper pack]  | 0     | 3 [Metal]   | 0     | 4 [Glass]    | 0     |\n",
      "| 5 [Plastic]       | 0     | 6 [Styrofoam] | 0     | 7 [Plastic bag] | 0     | 8 [Battery] | 0     | 9 [Clothing] | 0     |\n",
      "|                   |       |               |       |                 |       |             |       |              |       |\n",
      "| -1 background     | 4871  |               |       |                 |       |             |       |              |       |\n",
      "+-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+\n"
     ]
    }
   ],
   "source": [
    "print(data_loader.dataset)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: ./work_dirs/deformable_detr_twostage_refine_r50_16X2_50e_coco/latest.pth\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = os.path.join(cfg.work_dir, f'{epoch}.pth')\n",
    "\n",
    "model = build_detector(cfg.model, test_cfg=cfg.get('test_cfg')) # build detector\n",
    "checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu') # ckpt load\n",
    "\n",
    "model.CLASSES = dataset.CLASSES\n",
    "model = MMDataParallel(model.cuda(), device_ids=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                ] 3/4871, 7.5 task/s, elapsed: 0s, ETA:   646s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/baseline/mmdetection/mmdet/models/utils/positional_encoding.py:81: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_t = self.temperature**(2 * (dim_t // 2) / self.num_feats)\n",
      "/data/ephemeral/home/baseline/mmdetection/mmdet/models/utils/transformer.py:883: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_t = temperature**(2 * (dim_t // 2) / num_pos_feats)\n",
      "/data/ephemeral/home/baseline/mmdetection/mmdet/models/dense_heads/detr_head.py:666: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bbox_index = indexes // self.num_classes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>] 4871/4871, 15.6 task/s, elapsed: 312s, ETA:     0s"
     ]
    }
   ],
   "source": [
    "output = single_gpu_test(model, data_loader, show_score_thr=0.05) # output 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PredictionString</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 0.31805477 244.37642 684.1408 297.78598 751....</td>\n",
       "      <td>test/0000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 0.5475998 748.8038 655.8013 897.96204 987.28...</td>\n",
       "      <td>test/0001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 0.50443953 89.39138 273.55756 423.73456 602....</td>\n",
       "      <td>test/0002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0 0.032460466 0.0 0.9500427 912.6985 817.7748 ...</td>\n",
       "      <td>test/0003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 0.45714805 191.91547 251.0104 873.99384 769....</td>\n",
       "      <td>test/0004.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    PredictionString       image_id\n",
       "0  0 0.31805477 244.37642 684.1408 297.78598 751....  test/0000.jpg\n",
       "1  0 0.5475998 748.8038 655.8013 897.96204 987.28...  test/0001.jpg\n",
       "2  0 0.50443953 89.39138 273.55756 423.73456 602....  test/0002.jpg\n",
       "3  0 0.032460466 0.0 0.9500427 912.6985 817.7748 ...  test/0003.jpg\n",
       "4  0 0.45714805 191.91547 251.0104 873.99384 769....  test/0004.jpg"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submission 양식에 맞게 output 후처리\n",
    "prediction_strings = []\n",
    "file_names = []\n",
    "coco = COCO(cfg.data.test.ann_file)\n",
    "img_ids = coco.getImgIds()\n",
    "\n",
    "class_num = 10\n",
    "\n",
    "for i, out in enumerate(output):\n",
    "    prediction_string = ''\n",
    "    image_info = coco.loadImgs(coco.getImgIds(imgIds=img_ids[i]))[0]\n",
    "    \n",
    "    for j in range(class_num):\n",
    "        for o in out[j]:\n",
    "            prediction_string += str(j) + ' ' + str(o[4]) + ' ' + str(o[0]) + ' ' + str(o[1]) + ' ' + str(\n",
    "                o[2]) + ' ' + str(o[3]) + ' '\n",
    "        \n",
    "    prediction_strings.append(prediction_string)\n",
    "    file_names.append(image_info['file_name'])\n",
    "\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['PredictionString'] = prediction_strings\n",
    "submission['image_id'] = file_names\n",
    "submission.to_csv(os.path.join(cfg.work_dir, f'submission_{epoch}.csv'), index=None)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
