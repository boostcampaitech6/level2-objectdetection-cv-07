{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.2\n",
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "print(mmcv.__version__)\n",
    "\n",
    "# 모듈 import\n",
    "\n",
    "from mmcv import Config\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)\n",
    "from mmdet.utils import get_device\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\", \n",
    "           \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\")\n",
    "\n",
    "# config file 들고오기\n",
    "cfg = Config.fromfile('./configs/retinanet/retinanet_r50_fpn_1x_coco.py')\n",
    "\n",
    "root='../../dataset/'\n",
    "\n",
    "# dataset config 수정\n",
    "cfg.data.train.classes = classes\n",
    "cfg.data.train.img_prefix = root\n",
    "#cfg.data.train.ann_file = root + 'train.json' # train json 정보\n",
    "cfg.data.train.ann_file = root + 'skfold/cv_train_skfold1.json'\n",
    "cfg.data.train.pipeline[2]['img_scale'] = (512,512) # Resize\n",
    "\n",
    "cfg.data.val.classes = classes\n",
    "cfg.data.val.img_prefix = root\n",
    "#cfg.data.val.ann_file = root + 'val.json' # val json 정보\n",
    "cfg.data.val.ann_file = root + 'skfold/cv_val_skfold1.json'\n",
    "cfg.data.val.pipeline[1]['img_scale'] = (512,512) # Resize\n",
    "\n",
    "cfg.data.test.classes = classes\n",
    "cfg.data.test.img_prefix = root\n",
    "cfg.data.test.ann_file = root + 'test.json' # test json 정보\n",
    "cfg.data.test.pipeline[1]['img_scale'] = (512,512) # Resize\n",
    "\n",
    "cfg.data.samples_per_gpu = 4\n",
    "\n",
    "cfg.seed = 2022\n",
    "cfg.gpu_ids = [0]\n",
    "cfg.work_dir = './work_dirs/retinanet_r50_fpn_1x_trash_skf1'\n",
    "\n",
    "cfg.model.bbox_head.num_classes = 10\n",
    "\n",
    "cfg.optimizer_config.grad_clip = dict(max_norm=35, norm_type=2)\n",
    "cfg.checkpoint_config = dict(max_keep_ckpts=3, interval=1)\n",
    "cfg.device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['samples_per_gpu', 'workers_per_gpu', 'train', 'val', 'test'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.keys()\n",
    "cfg.data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# build_dataset\n",
    "datasets = [build_dataset(cfg.data.train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "CocoDataset Train dataset with number of images 3914, and instance counts: \n",
       "+-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+\n",
       "| category          | count | category      | count | category        | count | category    | count | category     | count |\n",
       "+-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+\n",
       "| 0 [General trash] | 3161  | 1 [Paper]     | 5115  | 2 [Paper pack]  | 706   | 3 [Metal]   | 769   | 4 [Glass]    | 835   |\n",
       "| 5 [Plastic]       | 2350  | 6 [Styrofoam] | 1026  | 7 [Plastic bag] | 4151  | 8 [Battery] | 143   | 9 [Clothing] | 377   |\n",
       "+-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset 확인\n",
    "datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'ResNet', 'depth': 50, 'num_stages': 4, 'out_indices': (0, 1, 2, 3), 'frozen_stages': 1, 'norm_cfg': {'type': 'BN', 'requires_grad': True}, 'norm_eval': True, 'style': 'pytorch', 'init_cfg': {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}}\n",
      "PyTorch version: 1.12.1\n",
      "Torchvision version: 0.13.1\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(cfg.model.backbone)\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Torchvision version:\", torchvision.__version__)\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "# ResNet50 모델 불러오기\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "# 모델의 구조를 출력하여 모델이 제대로 로드되었는지 확인\n",
    "print(resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 15:45:09,771 - mmcv - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\n",
      "2024-01-16 15:45:09,773 - mmcv - INFO - load model from: torchvision://resnet50\n",
      "2024-01-16 15:45:09,774 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet50\n",
      "2024-01-16 15:45:09,863 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "2024-01-16 15:45:09,891 - mmcv - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "2024-01-16 15:45:09,948 - mmcv - INFO - initialize RetinaHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01, 'override': {'type': 'Normal', 'name': 'retina_cls', 'std': 0.01, 'bias_prob': 0.01}}\n",
      "2024-01-16 15:45:10,001 - mmcv - INFO - \n",
      "backbone.conv1.weight - torch.Size([64, 3, 7, 7]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,002 - mmcv - INFO - \n",
      "backbone.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,002 - mmcv - INFO - \n",
      "backbone.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,003 - mmcv - INFO - \n",
      "backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,004 - mmcv - INFO - \n",
      "backbone.layer1.0.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,004 - mmcv - INFO - \n",
      "backbone.layer1.0.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,005 - mmcv - INFO - \n",
      "backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,005 - mmcv - INFO - \n",
      "backbone.layer1.0.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,006 - mmcv - INFO - \n",
      "backbone.layer1.0.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,006 - mmcv - INFO - \n",
      "backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,007 - mmcv - INFO - \n",
      "backbone.layer1.0.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,008 - mmcv - INFO - \n",
      "backbone.layer1.0.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,008 - mmcv - INFO - \n",
      "backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,009 - mmcv - INFO - \n",
      "backbone.layer1.0.downsample.1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,009 - mmcv - INFO - \n",
      "backbone.layer1.0.downsample.1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,010 - mmcv - INFO - \n",
      "backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,010 - mmcv - INFO - \n",
      "backbone.layer1.1.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,011 - mmcv - INFO - \n",
      "backbone.layer1.1.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,011 - mmcv - INFO - \n",
      "backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,012 - mmcv - INFO - \n",
      "backbone.layer1.1.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,013 - mmcv - INFO - \n",
      "backbone.layer1.1.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,013 - mmcv - INFO - \n",
      "backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,014 - mmcv - INFO - \n",
      "backbone.layer1.1.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,014 - mmcv - INFO - \n",
      "backbone.layer1.1.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,015 - mmcv - INFO - \n",
      "backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,015 - mmcv - INFO - \n",
      "backbone.layer1.2.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,016 - mmcv - INFO - \n",
      "backbone.layer1.2.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,016 - mmcv - INFO - \n",
      "backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,017 - mmcv - INFO - \n",
      "backbone.layer1.2.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,018 - mmcv - INFO - \n",
      "backbone.layer1.2.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,018 - mmcv - INFO - \n",
      "backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,019 - mmcv - INFO - \n",
      "backbone.layer1.2.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,019 - mmcv - INFO - \n",
      "backbone.layer1.2.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,020 - mmcv - INFO - \n",
      "backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,020 - mmcv - INFO - \n",
      "backbone.layer2.0.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,021 - mmcv - INFO - \n",
      "backbone.layer2.0.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,021 - mmcv - INFO - \n",
      "backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,022 - mmcv - INFO - \n",
      "backbone.layer2.0.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,022 - mmcv - INFO - \n",
      "backbone.layer2.0.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,023 - mmcv - INFO - \n",
      "backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,024 - mmcv - INFO - \n",
      "backbone.layer2.0.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,024 - mmcv - INFO - \n",
      "backbone.layer2.0.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,025 - mmcv - INFO - \n",
      "backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,025 - mmcv - INFO - \n",
      "backbone.layer2.0.downsample.1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,026 - mmcv - INFO - \n",
      "backbone.layer2.0.downsample.1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,026 - mmcv - INFO - \n",
      "backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,027 - mmcv - INFO - \n",
      "backbone.layer2.1.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,027 - mmcv - INFO - \n",
      "backbone.layer2.1.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,028 - mmcv - INFO - \n",
      "backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,029 - mmcv - INFO - \n",
      "backbone.layer2.1.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,029 - mmcv - INFO - \n",
      "backbone.layer2.1.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,030 - mmcv - INFO - \n",
      "backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,030 - mmcv - INFO - \n",
      "backbone.layer2.1.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,031 - mmcv - INFO - \n",
      "backbone.layer2.1.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,031 - mmcv - INFO - \n",
      "backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,031 - mmcv - INFO - \n",
      "backbone.layer2.2.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,032 - mmcv - INFO - \n",
      "backbone.layer2.2.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,032 - mmcv - INFO - \n",
      "backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,033 - mmcv - INFO - \n",
      "backbone.layer2.2.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,033 - mmcv - INFO - \n",
      "backbone.layer2.2.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,033 - mmcv - INFO - \n",
      "backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,034 - mmcv - INFO - \n",
      "backbone.layer2.2.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,034 - mmcv - INFO - \n",
      "backbone.layer2.2.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,034 - mmcv - INFO - \n",
      "backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,035 - mmcv - INFO - \n",
      "backbone.layer2.3.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,035 - mmcv - INFO - \n",
      "backbone.layer2.3.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,036 - mmcv - INFO - \n",
      "backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,036 - mmcv - INFO - \n",
      "backbone.layer2.3.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,036 - mmcv - INFO - \n",
      "backbone.layer2.3.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,037 - mmcv - INFO - \n",
      "backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,037 - mmcv - INFO - \n",
      "backbone.layer2.3.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,038 - mmcv - INFO - \n",
      "backbone.layer2.3.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,038 - mmcv - INFO - \n",
      "backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,038 - mmcv - INFO - \n",
      "backbone.layer3.0.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,039 - mmcv - INFO - \n",
      "backbone.layer3.0.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,039 - mmcv - INFO - \n",
      "backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,040 - mmcv - INFO - \n",
      "backbone.layer3.0.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,040 - mmcv - INFO - \n",
      "backbone.layer3.0.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,040 - mmcv - INFO - \n",
      "backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,041 - mmcv - INFO - \n",
      "backbone.layer3.0.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,041 - mmcv - INFO - \n",
      "backbone.layer3.0.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,042 - mmcv - INFO - \n",
      "backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,042 - mmcv - INFO - \n",
      "backbone.layer3.0.downsample.1.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,042 - mmcv - INFO - \n",
      "backbone.layer3.0.downsample.1.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,043 - mmcv - INFO - \n",
      "backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,043 - mmcv - INFO - \n",
      "backbone.layer3.1.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,044 - mmcv - INFO - \n",
      "backbone.layer3.1.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,044 - mmcv - INFO - \n",
      "backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,044 - mmcv - INFO - \n",
      "backbone.layer3.1.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,045 - mmcv - INFO - \n",
      "backbone.layer3.1.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,045 - mmcv - INFO - \n",
      "backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,046 - mmcv - INFO - \n",
      "backbone.layer3.1.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,046 - mmcv - INFO - \n",
      "backbone.layer3.1.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,046 - mmcv - INFO - \n",
      "backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,047 - mmcv - INFO - \n",
      "backbone.layer3.2.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,047 - mmcv - INFO - \n",
      "backbone.layer3.2.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,048 - mmcv - INFO - \n",
      "backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,048 - mmcv - INFO - \n",
      "backbone.layer3.2.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,048 - mmcv - INFO - \n",
      "backbone.layer3.2.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,049 - mmcv - INFO - \n",
      "backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,049 - mmcv - INFO - \n",
      "backbone.layer3.2.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,050 - mmcv - INFO - \n",
      "backbone.layer3.2.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,050 - mmcv - INFO - \n",
      "backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,050 - mmcv - INFO - \n",
      "backbone.layer3.3.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,051 - mmcv - INFO - \n",
      "backbone.layer3.3.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,051 - mmcv - INFO - \n",
      "backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,051 - mmcv - INFO - \n",
      "backbone.layer3.3.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,052 - mmcv - INFO - \n",
      "backbone.layer3.3.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,052 - mmcv - INFO - \n",
      "backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,053 - mmcv - INFO - \n",
      "backbone.layer3.3.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,053 - mmcv - INFO - \n",
      "backbone.layer3.3.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,053 - mmcv - INFO - \n",
      "backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,054 - mmcv - INFO - \n",
      "backbone.layer3.4.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,054 - mmcv - INFO - \n",
      "backbone.layer3.4.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,055 - mmcv - INFO - \n",
      "backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,055 - mmcv - INFO - \n",
      "backbone.layer3.4.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,055 - mmcv - INFO - \n",
      "backbone.layer3.4.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,056 - mmcv - INFO - \n",
      "backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,056 - mmcv - INFO - \n",
      "backbone.layer3.4.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,057 - mmcv - INFO - \n",
      "backbone.layer3.4.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,057 - mmcv - INFO - \n",
      "backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,058 - mmcv - INFO - \n",
      "backbone.layer3.5.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,058 - mmcv - INFO - \n",
      "backbone.layer3.5.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,058 - mmcv - INFO - \n",
      "backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,059 - mmcv - INFO - \n",
      "backbone.layer3.5.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,059 - mmcv - INFO - \n",
      "backbone.layer3.5.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,060 - mmcv - INFO - \n",
      "backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,060 - mmcv - INFO - \n",
      "backbone.layer3.5.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,060 - mmcv - INFO - \n",
      "backbone.layer3.5.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,061 - mmcv - INFO - \n",
      "backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,061 - mmcv - INFO - \n",
      "backbone.layer4.0.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,061 - mmcv - INFO - \n",
      "backbone.layer4.0.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,062 - mmcv - INFO - \n",
      "backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,062 - mmcv - INFO - \n",
      "backbone.layer4.0.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,063 - mmcv - INFO - \n",
      "backbone.layer4.0.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,063 - mmcv - INFO - \n",
      "backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,064 - mmcv - INFO - \n",
      "backbone.layer4.0.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,064 - mmcv - INFO - \n",
      "backbone.layer4.0.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,064 - mmcv - INFO - \n",
      "backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,065 - mmcv - INFO - \n",
      "backbone.layer4.0.downsample.1.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,065 - mmcv - INFO - \n",
      "backbone.layer4.0.downsample.1.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,066 - mmcv - INFO - \n",
      "backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,066 - mmcv - INFO - \n",
      "backbone.layer4.1.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,066 - mmcv - INFO - \n",
      "backbone.layer4.1.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,067 - mmcv - INFO - \n",
      "backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,067 - mmcv - INFO - \n",
      "backbone.layer4.1.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,067 - mmcv - INFO - \n",
      "backbone.layer4.1.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,068 - mmcv - INFO - \n",
      "backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,078 - mmcv - INFO - \n",
      "backbone.layer4.1.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,079 - mmcv - INFO - \n",
      "backbone.layer4.1.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,079 - mmcv - INFO - \n",
      "backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,080 - mmcv - INFO - \n",
      "backbone.layer4.2.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,080 - mmcv - INFO - \n",
      "backbone.layer4.2.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,080 - mmcv - INFO - \n",
      "backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,081 - mmcv - INFO - \n",
      "backbone.layer4.2.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,081 - mmcv - INFO - \n",
      "backbone.layer4.2.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,082 - mmcv - INFO - \n",
      "backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,082 - mmcv - INFO - \n",
      "backbone.layer4.2.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,082 - mmcv - INFO - \n",
      "backbone.layer4.2.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from torchvision://resnet50 \n",
      " \n",
      "2024-01-16 15:45:10,083 - mmcv - INFO - \n",
      "neck.lateral_convs.0.conv.weight - torch.Size([256, 512, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-01-16 15:45:10,083 - mmcv - INFO - \n",
      "neck.lateral_convs.0.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of RetinaNet  \n",
      " \n",
      "2024-01-16 15:45:10,084 - mmcv - INFO - \n",
      "neck.lateral_convs.1.conv.weight - torch.Size([256, 1024, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-01-16 15:45:10,084 - mmcv - INFO - \n",
      "neck.lateral_convs.1.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of RetinaNet  \n",
      " \n",
      "2024-01-16 15:45:10,084 - mmcv - INFO - \n",
      "neck.lateral_convs.2.conv.weight - torch.Size([256, 2048, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-01-16 15:45:10,085 - mmcv - INFO - \n",
      "neck.lateral_convs.2.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of RetinaNet  \n",
      " \n",
      "2024-01-16 15:45:10,085 - mmcv - INFO - \n",
      "neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-01-16 15:45:10,085 - mmcv - INFO - \n",
      "neck.fpn_convs.0.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of RetinaNet  \n",
      " \n",
      "2024-01-16 15:45:10,086 - mmcv - INFO - \n",
      "neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-01-16 15:45:10,086 - mmcv - INFO - \n",
      "neck.fpn_convs.1.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of RetinaNet  \n",
      " \n",
      "2024-01-16 15:45:10,087 - mmcv - INFO - \n",
      "neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-01-16 15:45:10,087 - mmcv - INFO - \n",
      "neck.fpn_convs.2.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of RetinaNet  \n",
      " \n",
      "2024-01-16 15:45:10,087 - mmcv - INFO - \n",
      "neck.fpn_convs.3.conv.weight - torch.Size([256, 2048, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-01-16 15:45:10,088 - mmcv - INFO - \n",
      "neck.fpn_convs.3.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of RetinaNet  \n",
      " \n",
      "2024-01-16 15:45:10,088 - mmcv - INFO - \n",
      "neck.fpn_convs.4.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-01-16 15:45:10,089 - mmcv - INFO - \n",
      "neck.fpn_convs.4.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of RetinaNet  \n",
      " \n",
      "2024-01-16 15:45:10,089 - mmcv - INFO - \n",
      "bbox_head.cls_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2024-01-16 15:45:10,089 - mmcv - INFO - \n",
      "bbox_head.cls_convs.0.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of RetinaNet  \n",
      " \n",
      "2024-01-16 15:45:10,090 - mmcv - INFO - \n",
      "bbox_head.cls_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2024-01-16 15:45:10,090 - mmcv - INFO - \n",
      "bbox_head.cls_convs.1.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of RetinaNet  \n",
      " \n",
      "2024-01-16 15:45:10,091 - mmcv - INFO - \n",
      "bbox_head.cls_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2024-01-16 15:45:10,091 - mmcv - INFO - \n",
      "bbox_head.cls_convs.2.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of RetinaNet  \n",
      " \n",
      "2024-01-16 15:45:10,091 - mmcv - INFO - \n",
      "bbox_head.cls_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2024-01-16 15:45:10,092 - mmcv - INFO - \n",
      "bbox_head.cls_convs.3.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of RetinaNet  \n",
      " \n",
      "2024-01-16 15:45:10,092 - mmcv - INFO - \n",
      "bbox_head.reg_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2024-01-16 15:45:10,092 - mmcv - INFO - \n",
      "bbox_head.reg_convs.0.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of RetinaNet  \n",
      " \n",
      "2024-01-16 15:45:10,093 - mmcv - INFO - \n",
      "bbox_head.reg_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2024-01-16 15:45:10,093 - mmcv - INFO - \n",
      "bbox_head.reg_convs.1.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of RetinaNet  \n",
      " \n",
      "2024-01-16 15:45:10,094 - mmcv - INFO - \n",
      "bbox_head.reg_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2024-01-16 15:45:10,094 - mmcv - INFO - \n",
      "bbox_head.reg_convs.2.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of RetinaNet  \n",
      " \n",
      "2024-01-16 15:45:10,095 - mmcv - INFO - \n",
      "bbox_head.reg_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2024-01-16 15:45:10,095 - mmcv - INFO - \n",
      "bbox_head.reg_convs.3.conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of RetinaNet  \n",
      " \n",
      "2024-01-16 15:45:10,095 - mmcv - INFO - \n",
      "bbox_head.retina_cls.weight - torch.Size([99, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \n",
      " \n",
      "2024-01-16 15:45:10,096 - mmcv - INFO - \n",
      "bbox_head.retina_cls.bias - torch.Size([99]): \n",
      "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \n",
      " \n",
      "2024-01-16 15:45:10,096 - mmcv - INFO - \n",
      "bbox_head.retina_reg.weight - torch.Size([36, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2024-01-16 15:45:10,096 - mmcv - INFO - \n",
      "bbox_head.retina_reg.bias - torch.Size([36]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n"
     ]
    }
   ],
   "source": [
    "# 모델 build 및 pretrained network 불러오기\n",
    "model = build_detector(cfg.model)\n",
    "model.init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 15:45:20,157 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
      "2024-01-16 15:45:20,159 - mmdet - INFO - Start running, host: root@instance-5252, work_dir: /data/ephemeral/home/baseline/mmdetection/work_dirs/retinanet_r50_fpn_1x_trash2\n",
      "2024-01-16 15:45:20,160 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2024-01-16 15:45:20,160 - mmdet - INFO - workflow: [('train', 1)], max: 12 epochs\n",
      "2024-01-16 15:45:20,161 - mmdet - INFO - Checkpoints will be saved to /data/ephemeral/home/baseline/mmdetection/work_dirs/retinanet_r50_fpn_1x_trash2 by HardDiskBackend.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The `num_classes` (11) in RetinaHead of MMDataParallel does not matches the length of `CLASSES` 10) in CocoDataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistributed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/baseline/mmdetection/mmdet/apis/train.py:244\u001b[0m, in \u001b[0;36mtrain_detector\u001b[0;34m(model, dataset, cfg, distributed, validate, timestamp, meta)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mload_from:\n\u001b[1;32m    243\u001b[0m     runner\u001b[38;5;241m.\u001b[39mload_checkpoint(cfg\u001b[38;5;241m.\u001b[39mload_from)\n\u001b[0;32m--> 244\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/ephemeral/conda_envs/openmmlab/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py:136\u001b[0m, in \u001b[0;36mEpochBasedRunner.run\u001b[0;34m(self, data_loaders, workflow, max_epochs, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_epochs:\n\u001b[1;32m    135\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m             \u001b[43mepoch_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loaders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# wait for some hooks like loggers to finish\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_run\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/data/ephemeral/conda_envs/openmmlab/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py:47\u001b[0m, in \u001b[0;36mEpochBasedRunner.train\u001b[0;34m(self, data_loader, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_loader \u001b[38;5;241m=\u001b[39m data_loader\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_iters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_epochs \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_loader)\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbefore_train_epoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Prevent possible deadlock during epoch transition\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_loader):\n",
      "File \u001b[0;32m/data/ephemeral/conda_envs/openmmlab/lib/python3.8/site-packages/mmcv/runner/base_runner.py:317\u001b[0m, in \u001b[0;36mBaseRunner.call_hook\u001b[0;34m(self, fn_name)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call all hooks.\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \n\u001b[1;32m    312\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m    fn_name (str): The function name in each hook to be called, such as\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m        \"before_train_epoch\".\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hooks:\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/baseline/mmdetection/mmdet/datasets/utils.py:158\u001b[0m, in \u001b[0;36mNumClassCheckHook.before_train_epoch\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbefore_train_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m, runner):\n\u001b[1;32m    153\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check whether the training dataset is compatible with head.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m        runner (obj:`EpochBasedRunner`): Epoch based Runner.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/baseline/mmdetection/mmdet/datasets/utils.py:144\u001b[0m, in \u001b[0;36mNumClassCheckHook._check_head\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_modules():\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_classes\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    143\u001b[0m             module, (RPNHead, VGG, FusedSemanticHead, GARPNHead)):\n\u001b[0;32m--> 144\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnum_classes \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mCLASSES), \\\n\u001b[1;32m    145\u001b[0m             (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe `num_classes` (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39mnum_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) in \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    146\u001b[0m              \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    147\u001b[0m              \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not matches \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    148\u001b[0m              \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe length of `CLASSES` \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    149\u001b[0m              \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mCLASSES)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) in \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    150\u001b[0m              \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: The `num_classes` (11) in RetinaHead of MMDataParallel does not matches the length of `CLASSES` 10) in CocoDataset"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "train_detector(model, datasets[0], cfg, distributed=False, validate=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "980dec4bdc0f65d3f181e5891661df87e8769cde5e79cd54bc145a7f830b2685"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
